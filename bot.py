# FILE BOT CH√çNH (CHU·∫®N DAY 13 - v3.0 Hybrid - T√≠ch h·ª£p GEMINI)
from scrapers import scrape_python_news # <-- File m·ªõi t·∫°o
import sqlite3
from db_collector import CollectorV2
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import (
    Application, CommandHandler, MessageHandler, filters,
    ContextTypes, CallbackQueryHandler
)
import datetime
import logging
import os
import httpx  # C·∫ßn cho th∆∞ vi·ªán telegram (v√† sau n√†y)
import google.generativeai as genai  # <-- M·ªöI (Day 13)

# --- C·∫§U H√åNH (N√ÇNG C·∫§P Day 13) ---
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")  # <-- M·ªöI (Day 13)
DATABASE_URL = os.getenv("DATABASE_URL") # ƒê·ªçc URL database t·ª´ m√¥i tr∆∞·ªùng

if DATABASE_URL and DATABASE_URL.startswith("postgres://"):
    DATABASE_URL = DATABASE_URL.replace("postgres://", "postgresql://", 1)

# --- THI·∫æT L·∫¨P LOGGING ---
logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s", level=logging.INFO
)
logger = logging.getLogger(__name__)

# --- KI·ªÇM TRA BI·∫æN M√îI TR∆Ø·ªúNG ---
if not TELEGRAM_BOT_TOKEN:
    logger.error("L·ªñI: Bi·∫øn m√¥i tr∆∞·ªùng TELEGRAM_BOT_TOKEN kh√¥ng ƒë∆∞·ª£c thi·∫øt l·∫≠p.")
    exit()

if not GEMINI_API_KEY:
    logger.error("L·ªñI: Bi·∫øn m√¥i tr∆∞·ªùng GEMINI_API_KEY kh√¥ng ƒë∆∞·ª£c thi·∫øt l·∫≠p.")
    logger.error("H√£y l·∫•y API Key t·ª´ Google AI Studio v√† th√™m v√†o file .env")
    exit()

# --- C·∫§U H√åNH GEMINI v3.0 (M·ªöI Day 13) ---
try:
    genai.configure(api_key=GEMINI_API_KEY)

    # C·∫•u h√¨nh h·ªá th·ªëng (System Prompt) cho AI
    system_prompt = (
        "B·∫°n l√† 'AI Mentor', m·ªôt tr·ª£ l√Ω h·ªçc t·∫≠p th√¢n thi·ªán v√† chuy√™n nghi·ªáp. "
        "H√£y lu√¥n tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát. "
        "Gi·ªØ c√¢u tr·∫£ l·ªùi ng·∫Øn g·ªçn, t·∫≠p trung v√†o vi·ªác gi·∫£i th√≠ch kh√°i ni·ªám "
        "ho·∫∑c tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi h·ªçc. Kh√¥ng c·∫ßn ch√†o h·ªèi l·∫°i."
    )

    model_v3 = genai.GenerativeModel(
        model_name="gemini-2.5-flash-lite",  # D√πng Flash cho t·ªëc ƒë·ªô
        system_instruction=system_prompt
    )
    logger.info("ƒê√£ c·∫•u h√¨nh v√† kh·ªüi t·∫°o th√†nh c√¥ng Gemini AI v3.0.")
except Exception as e:
    logger.error(f"L·ªói kh·ªüi t·∫°o Gemini: {e}", exc_info=True)
    model_v3 = None  # ƒê√°nh d·∫•u l√† b·ªã l·ªói

# --- K·∫æT N·ªêI DATABASE V2.0 (Nh∆∞ c≈©) ---
try:
    db = CollectorV2(DATABASE_URL) # Truy·ªÅn URL v√†o
    db.setup_database()
    content_records = db.get_all_content()
    logger.info(f"ƒê√£ t·∫£i {len(content_records)} g·ª£i √Ω t·ª´ cache SQLite (v2.0).")
except Exception as e:
    logger.error(f"L·ªñI KH·ªûI ƒê·ªòNG: Kh√¥ng th·ªÉ k·∫øt n·ªëi DB {DATABASE_URL}: {e}", exc_info=True)
    exit()

if not DATABASE_URL:
    logger.error("L·ªñI: Bi·∫øn m√¥i tr∆∞·ªùng DATABASE_URL kh√¥ng ƒë∆∞·ª£c thi·∫øt l·∫≠p.")
    exit()

# --- B·ªò M√ÅY G·ª¢I √ù v2.0 (Day 09 - Gi·ªØ nguy√™n) ---
def get_suggestion_engine(message_text: str) -> tuple:
    # (H√†m n√†y gi·ªØ nguy√™n 100% nh∆∞ Day 12)
    lower_message = message_text.lower()
    found_suggestions = []
    for record in content_records:
        keyword = str(record.get('Keyword', '')).lower()
        if keyword and keyword in lower_message:
            found_suggestions.append(record)
    if not found_suggestions:
        return None, None, None
    found_suggestions.sort(key=lambda x: x.get('Rating_Score', 0), reverse=True)
    best_suggestion = found_suggestions[0]
    return (
        best_suggestion.get('Suggestion_Text'),
        best_suggestion.get('Suggestion_Link'),
        best_suggestion.get('Suggestion_ID')
    )
# --- JOB 1: AUTO FEED (C√†o d·ªØ li·ªáu) ---
async def auto_feed_job(context: ContextTypes.DEFAULT_TYPE):
    logger.info("JOB: B·∫Øt ƒë·∫ßu c√†o d·ªØ li·ªáu t·ª± ƒë·ªông...")

    # 1. Ch·∫°y scraper
    items = scrape_python_news()

    if items:
        # 2. L∆∞u v√†o DB (c√≥ check tr√πng)
        count = db.import_content_batch(items)
        msg = f"ƒê√£ c√†o ƒë∆∞·ª£c {len(items)} b√†i, th√™m m·ªõi {count} b√†i."
        logger.info(msg)

        # 3. Ghi log s·ª©c kh·ªèe
        db.log_health("Scraper", "OK", msg)
    else:
        db.log_health("Scraper", "WARNING", "Kh√¥ng c√†o ƒë∆∞·ª£c b√†i n√†o.")

# --- JOB 2: ALIVE CHECK (Ki·ªÉm tra s·ª©c s·ªëng) ---
async def alive_check_job(context: ContextTypes.DEFAULT_TYPE):
    # Ch·ªâ ƒë∆°n gi·∫£n l√† ghi v√†o DB ƒë·ªÉ bi·∫øt bot c√≤n ch·∫°y
    db.log_health("System", "ALIVE", "Bot ƒëang ch·∫°y ·ªïn ƒë·ªãnh.")
    logger.info("JOB: Alive check logged.")

# --- B·ªò N√ÉO v1.0 (Day 04 - Gi·ªØ l·∫°i l√†m Fallback) ---
def get_ai_feedback_v1_0(message_text: str) -> str:
    # (H√†m n√†y gi·ªØ nguy√™n 100% nh∆∞ Day 12)
    lower_message = message_text.lower()
    if "xin ch√†o" in lower_message:
        return "Ch√†o b·∫°n, r·∫•t vui ƒë∆∞·ª£c h·ªó tr·ª£ b·∫°n. H√¥m nay b·∫°n mu·ªën h·ªçc g√¨?"
    elif "c·∫£m ∆°n" in lower_message:
        return "Kh√¥ng c√≥ g√¨! M√¨nh lu√¥n s·∫µn s√†ng gi√∫p ƒë·ª°."
    # ... (c√°c logic if-else kh√°c)
    else:
        return "C·∫£m ∆°n b·∫°n ƒë√£ chia s·∫ª. M√¨nh ƒë√£ ghi nh·∫≠n th√¥ng tin n√†y."


# --- B·ªò N√ÉO v3.0 (M·ªöI Day 13) ---
async def get_gemini_feedback_v3(message_text: str, history: list) -> str:
    if not model_v3:
        raise Exception("M√¥ h√¨nh Gemini v3.0 ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o.")

    # 1. Chuy·ªÉn ƒë·ªïi l·ªãch s·ª≠ chat
    # Gemini c·∫ßn: [{'role': 'user', 'parts': [text]}, {'role': 'model', 'parts': [text]}]
    gemini_history = []
    for msg in history:
        role = "user" if msg["role"] == "user" else "model"
        gemini_history.append({
            "role": role,
            "parts": [msg["content"]]
        })

    # 2. B·∫Øt ƒë·∫ßu phi√™n chat m·ªõi v·ªõi l·ªãch s·ª≠ c≈©
    chat_session = model_v3.start_chat(history=gemini_history)

    # 3. G·ª≠i tin nh·∫Øn m·ªõi v√† ch·ªù ph·∫£n h·ªìi (async)
    response = await chat_session.send_message_async(message_text)

    return response.text


# --- SMART SCHEDULER JOB (Day 11 - Gi·ªØ nguy√™n) ---
async def smart_scheduler_job(context: ContextTypes.DEFAULT_TYPE):
    # (H√†m n√†y gi·ªØ nguy√™n 100% nh∆∞ Day 12)
    logger.info("SCHEDULER: ƒêang ch·∫°y Job ki·ªÉm tra ng∆∞·ªùi d√πng...")
    inactive_users = db.get_inactive_users(days_inactive=3)
    if not inactive_users:
        logger.info("SCHEDULER: Kh√¥ng c√≥ ai kh√¥ng ho·∫°t ƒë·ªông. K·∫øt th√∫c Job.")
        return
    # ... (logic g·ª≠i tin nh·∫Øn)


# --- H√ÄM X·ª¨ L√ù TIN NH·∫ÆN (N√ÇNG C·∫§P "HYBRID" v3.0) ---
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    message = update.message
    user_id = message.from_user.id
    username = message.from_user.username or message.from_user.first_name
    message_text = message.text

    logger.info(f"[v3.0] Nh·∫≠n tin nh·∫Øn t·ª´ [{username}]: {message_text}")
    history = context.user_data.setdefault('history', [])
    history.append({"role": "user", "content": message_text})

    final_feedback = ""
    callback_type = "std"
    callback_id = ""

    # --- LOGIC HYBRID ---

    # ∆ØU TI√äN 1: T√¨m trong DB v2.0 (Nhanh, R·∫ª, Ch√≠nh x√°c)
    sugg_text, sugg_link, sugg_id = get_suggestion_engine(message_text)

    if sugg_id:
        # T√¨m th·∫•y trong DB, d√πng n√≥
        final_feedback = f"M√¨nh nghƒ© ƒë√¢y l√† n·ªôi dung b·∫°n ƒëang t√¨m:\n\nüí° **{sugg_text}**\n{sugg_link}"
        callback_type = "sugg"
        callback_id = sugg_id
        logger.info(f"ƒê√£ t√¨m th·∫•y v2.0 (local): {sugg_id}")

    else:
        # ∆ØU TI√äN 2: Kh√¥ng t√¨m th·∫•y, g·ªçi GEMINI v3.0 (Th√¥ng minh)
        try:
            logger.info("v2.0 kh√¥ng c√≥. ƒêang g·ªçi Gemini v3.0...")
            # L·∫•y 10 tin nh·∫Øn cu·ªëi l√†m ng·ªØ c·∫£nh
            gemini_response = await get_gemini_feedback_v3(message_text, history[-10:])
            final_feedback = gemini_response
            callback_type = "std"  # Feedback c·ªßa Gemini l√† "std" (chung)
            logger.info("Gemini v3.0 ƒë√£ tr·∫£ l·ªùi.")

        except Exception as e:
            # ∆ØU TI√äN 3: Gemini l·ªói, d√πng v1.0 (D·ª± ph√≤ng)
            logger.error(f"L·ªói g·ªçi Gemini v3.0: {e}", exc_info=True)
            logger.info("D√πng fallback v1.0 (rule-based).")
            final_feedback = get_ai_feedback_v1_0(message_text)  # D√πng v1.0 l√†m fallback
            callback_type = "std"

    # --- K·∫øt th√∫c Logic Hybrid ---

    # C·∫≠p nh·∫≠t l·ªãch s·ª≠ (v·ªõi c√¢u tr·∫£ l·ªùi cu·ªëi c√πng)
    history.append({"role": "ai", "content": final_feedback})
    context.user_data['history'] = history[-20:]  # Nh·ªõ 20 tin nh·∫Øn

    # Ghi log v√†o SQLite
    try:
        db.log_message(user_id, username, message_text, final_feedback)
    except Exception as e:
        logger.error(f"L·ªñI GHI LOG SQLite: {e}", exc_info=True)
        await message.reply_text("L·ªói nghi√™m tr·ªçng: Kh√¥ng th·ªÉ ghi log. Vui l√≤ng b√°o admin.")
        return

    # G·ª≠i tin nh·∫Øn v√† n√∫t (nh∆∞ c≈©)
    keyboard = [[
        InlineKeyboardButton("üëç H·ªØu √≠ch", callback_data=f"fb_{callback_type}_{callback_id}_good"),
        InlineKeyboardButton("üëé Kh√¥ng h·ªØu √≠ch", callback_data=f"fb_{callback_type}_{callback_id}_bad"),
    ]]
    reply_markup = InlineKeyboardMarkup(keyboard)

    # C·∫ßn parse_mode="Markdown" ƒë·ªÉ Gemini hi·ªÉn th·ªã code (```) ho·∫∑c **in ƒë·∫≠m**
    await message.reply_text(final_feedback, reply_markup=reply_markup, parse_mode="Markdown")


# --- H√ÄM X·ª¨ L√ù N√öT B·∫§M (v2.0 - Gi·ªØ nguy√™n) ---
async def button_click(update: Update, context: ContextTypes.DEFAULT_TYPE):
    # (H√†m n√†y gi·ªØ nguy√™n 100% nh∆∞ Day 12)
    # N√≥ v·∫´n ho·∫°t ƒë·ªông v√¨ logic "Learning" (update_suggestion_score)
    # ch·ªâ k√≠ch ho·∫°t khi feedback_type == "sugg" (∆Øu ti√™n 1)
    # ...
    query = update.callback_query
    await query.answer()
    data = query.data
    logger.info(f"Nh·∫≠n callback_data: {data}")
    parts = data.split('_')
    feedback_type = parts[1]
    rating = parts.pop()
    ai_text = query.message.text
    user_id = query.from_user.id
    sugg_id_logged = None
    if feedback_type == "sugg":
        sugg_id = "_".join(parts[2:])
        sugg_id_logged = sugg_id
        try:
            db.update_suggestion_score(sugg_id_logged, rating)
            global content_records
            for record in content_records:
                if record.get('Suggestion_ID') == sugg_id_logged:
                    record['Rating_Score'] += 1 if rating == "good" else -1
                    break
            logger.info(f"ƒê√£ c·∫≠p nh·∫≠t ƒëi·ªÉm v2.0 cho {sugg_id_logged}")
        except Exception as e:
            logger.error(f"L·ªói c·∫≠p nh·∫≠t ƒëi·ªÉm v2.0 cho {sugg_id_logged}: {e}", exc_info=True)
    try:
        db.log_feedback(user_id, ai_text, rating, sugg_id_logged)
        logger.info(f"ƒê√£ ghi feedback v2.0 v√†o SQLite.")
        await query.edit_message_text(text=f"{ai_text}\n\n[C·∫£m ∆°n b·∫°n ƒë√£ ƒë√°nh gi√°!]")
    except Exception as e:
        logger.error(f"L·ªói ghi feedback v2.0: {e}", exc_info=True)
        await query.edit_message_text(text=f"{ai_text}\n\n[L·ªói: Kh√¥ng th·ªÉ l∆∞u ƒë√°nh gi√°. Nh∆∞ng v·∫´n c·∫£m ∆°n b·∫°n!]")


# --- C√ÅC H√ÄM X·ª¨ L√ù KH√ÅC (Gi·ªØ nguy√™n) ---
async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "Ch√†o b·∫°n! T√¥i l√† AI Mentor Bot v3.0. H√£y h·ªèi t√¥i b·∫•t c·ª© ƒëi·ªÅu g√¨!")  # C·∫≠p nh·∫≠t tin nh·∫Øn ch√†o m·ª´ng


async def non_text_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("M√¨nh hi·ªán ch·ªâ hi·ªÉu ƒë∆∞·ª£c tin nh·∫Øn vƒÉn b·∫£n th√¥i! üòä")


async def unknown_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("R·∫•t ti·∫øc, m√¨nh kh√¥ng hi·ªÉu l·ªánh ƒë√≥. B·∫°n ch·ªâ c·∫ßn nh·∫Øn tin b√¨nh th∆∞·ªùng th√¥i nh√©.")


# --- H√ÄM CH√çNH ƒê·ªÇ CH·∫†Y BOT (Gi·ªØ nguy√™n) ---
def main():
    logger.info("ƒêang kh·ªüi ƒë·ªông bot (v3.0 - Hybrid)...")
    application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()
    # --- SCHEDULERS ---
    job_queue = application.job_queue

    # 1. Nh·∫Øc nh·ªü h·ªçc t·∫≠p (C≈©) - Ch·∫°y m·ªói 24h
    job_queue.run_repeating(smart_scheduler_job, interval=86400, first=10)

    # 2. Alive Check (M·ªõi) - Ch·∫°y m·ªói 1 gi·ªù (3600s)
    job_queue.run_repeating(alive_check_job, interval=3600, first=20)

    # 3. Auto Feed Scraper (M·ªõi) - Ch·∫°y m·ªói 6 gi·ªù (21600s)
    job_queue.run_repeating(auto_feed_job, interval=21600, first=30)

    logger.info("ƒê√£ k√≠ch ho·∫°t t·∫•t c·∫£ Scheduler (Reminder, Alive, Scraper).")
    job_queue.run_repeating(smart_scheduler_job, interval=86400, first=10)
    logger.info("ƒê√£ k√≠ch ho·∫°t Smart Scheduler (ch·∫°y m·ªói 24h, b·∫Øt ƒë·∫ßu sau 10s).")
    application.add_handler(CommandHandler("start", start_command))
    application.add_handler(CallbackQueryHandler(button_click, pattern="^fb_"))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    application.add_handler(MessageHandler(filters.Sticker.ALL | filters.PHOTO, non_text_message))
    application.add_handler(MessageHandler(filters.COMMAND, unknown_command))
    logger.info("Bot (v3.0) ƒëang ch·∫°y! Nh·∫•n Ctrl+C ƒë·ªÉ d·ª´ng.")
    application.run_polling()


if __name__ == "__main__":
    main()