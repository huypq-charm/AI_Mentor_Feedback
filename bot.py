# FILE BOT CH√çNH (CHU·∫®N DAY 21 - Multi-Source Scraper)

import sqlite3
from db_collector import CollectorV2
# [DAY 21] Import h√†m c√†o ƒëa ngu·ªìn
from scrapers import scrape_all_sources
from retry_manager import RetryManager

from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import (
    Application, CommandHandler, MessageHandler, filters,
    ContextTypes, CallbackQueryHandler
)
import datetime
import logging
import os
import httpx
import google.generativeai as genai

# --- C·∫§U H√åNH ---
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
DATABASE_URL = os.getenv("DATABASE_URL")

# ‚ö†Ô∏è THAY B·∫∞NG ID TELEGRAM C·ª¶A B·∫†N
ADMIN_IDS = [5929406140]

# --- C·∫§U H√åNH LOGGING ---
logging.basicConfig(
    format="%(asctime)s [%(levelname)s] [%(name)s] %(message)s",
    level=logging.INFO,
    datefmt="%Y-%m-%d %H:%M:%S"
)
# T·∫Øt b·ªõt log r√°c
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("apscheduler").setLevel(logging.WARNING)
logging.getLogger("googleapiclient").setLevel(logging.WARNING)
logging.getLogger("urllib3").setLevel(logging.WARNING)

logger = logging.getLogger("AI_Mentor_Bot")

# --- BI·∫æN C·ªú (LOCKS) ---
job_locks = {
    "scheduler": False,
    "scraper": False
}

# --- KH·ªûI T·∫†O ---
if not TELEGRAM_BOT_TOKEN or not GEMINI_API_KEY:
    logger.error("L·ªói: Thi·∫øu API Key.")
    exit()

if DATABASE_URL and DATABASE_URL.startswith("postgres://"):
    DATABASE_URL = DATABASE_URL.replace("postgres://", "postgresql://", 1)

# 1. Database
try:
    db = CollectorV2(DATABASE_URL)
    db.setup_database()
    content_records = db.get_all_content()
    logger.info(f"DB: ƒê√£ t·∫£i {len(content_records)} g·ª£i √Ω t·ª´ cache.")
except Exception as e:
    logger.error(f"L·ªñI KH·ªûI ƒê·ªòNG DB: {e}", exc_info=True)
    exit()

# 2. Retry Manager
retry_mgr = RetryManager()

# 3. Gemini AI
try:
    genai.configure(api_key=GEMINI_API_KEY)
    system_prompt = """
    B·∫°n l√† AI Mentor, tr·ª£ l√Ω h·ªçc t·∫≠p chuy√™n nghi·ªáp.
    1. Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát.
    2. Gi·∫£i th√≠ch ng·∫Øn g·ªçn, d·ªÖ hi·ªÉu.
    3. N·∫øu c√≥ code, h√£y ƒë·ªÉ trong block code.
    4. Th√¢n thi·ªán v√† khuy·∫øn kh√≠ch ng∆∞·ªùi h·ªçc.
    """
    model_v3 = genai.GenerativeModel(
        model_name="models/gemini-flash-latest",
        system_instruction=system_prompt
    )
except Exception:
    model_v3 = None
    logger.warning("Gemini Error: Fallback Mode.")


# ==============================================================================
# HELPER FUNCTIONS
# ==============================================================================

async def send_message_safe(bot, chat_id, text, parse_mode=None):
    try:
        await bot.send_message(chat_id=chat_id, text=text, parse_mode=parse_mode)
        return True
    except Exception as e:
        logger.error(f"G·ª≠i tin th·∫•t b·∫°i cho {chat_id}: {e}")
        retry_mgr.add_message(chat_id, text, reason=e)
        return False


def get_suggestion_engine(message_text: str) -> tuple:
    lower_message = message_text.lower()
    found_suggestions = []
    for record in content_records:
        keyword = str(record.get('Keyword', '')).lower()
        if keyword and keyword in lower_message:
            found_suggestions.append(record)
    if not found_suggestions: return None, None, None
    found_suggestions.sort(key=lambda x: x.get('Rating_Score', 0), reverse=True)
    best = found_suggestions[0]
    return (best.get('Suggestion_Text'), best.get('Suggestion_Link'), best.get('Suggestion_ID'))


def get_ai_feedback_v1_0(message_text: str) -> str:
    if "xin ch√†o" in message_text.lower(): return "Ch√†o b·∫°n! B·∫°n c·∫ßn m√¨nh h·ªó tr·ª£ g√¨ h√¥m nay?"
    return "C·∫£m ∆°n b·∫°n ƒë√£ chia s·∫ª. M√¨nh ƒë√£ ghi nh·∫≠n th√¥ng tin n√†y."


async def get_gemini_feedback_v3(message_text: str, history: list) -> str:
    if not model_v3: raise Exception("Gemini ch∆∞a s·∫µn s√†ng.")
    gemini_history = []
    for msg in history:
        role = "user" if msg["role"] == "user" else "model"
        gemini_history.append({"role": role, "parts": [msg["content"]]})
    chat_session = model_v3.start_chat(history=gemini_history)
    response = await chat_session.send_message_async(message_text)
    return response.text


# ==============================================================================
# JOBS SCHEDULER
# ==============================================================================

# 1. Nh·∫Øc nh·ªü h·ªçc t·∫≠p
async def smart_scheduler_job(context: ContextTypes.DEFAULT_TYPE):
    if job_locks["scheduler"]: return
    job_locks["scheduler"] = True
    try:
        current_hour = datetime.datetime.now().hour
        if current_hour < 8 or current_hour > 21: return

        logger.info("SCHEDULER: Qu√©t ng∆∞·ªùi d√πng...")
        inactive_users = db.get_inactive_users(days_inactive=3)
        if inactive_users:
            count = 0
            msg = "Ch√†o b·∫°n, ƒë√£ l√¢u kh√¥ng th·∫•y b·∫°n t∆∞∆°ng t√°c. Ti·∫øp t·ª•c h·ªçc nh√©! üöÄ"
            for user in inactive_users:
                if await send_message_safe(context.bot, user['user_id'], msg):
                    count += 1
            logger.info(f"SCHEDULER: ƒê√£ nh·∫Øc nh·ªü {count} ng∆∞·ªùi.")
    except Exception as e:
        logger.error(f"L·ªói Scheduler: {e}")
    finally:
        job_locks["scheduler"] = False


# 2. Retry Job
async def retry_job(context: ContextTypes.DEFAULT_TYPE):
    messages = retry_mgr.pop_batch(limit=5)
    if messages:
        logger.info(f"RETRY: ƒêang th·ª≠ g·ª≠i l·∫°i {len(messages)} tin nh·∫Øn...")
        for item in messages:
            try:
                await context.bot.send_message(chat_id=item['chat_id'], text=item['text'], parse_mode="Markdown")
                logger.info(f"RETRY: Th√†nh c√¥ng cho {item['chat_id']}")
            except Exception as e:
                logger.error(f"RETRY Fail: {e}")


# 3. [DAY 21] Auto Feed Scraper (ƒêA NGU·ªíN)
async def auto_feed_job(context: ContextTypes.DEFAULT_TYPE):
    if job_locks["scraper"]:
        logger.warning("SCRAPER: Job tr∆∞·ªõc ch∆∞a xong. B·ªè qua.")
        return

    job_locks["scraper"] = True
    try:
        logger.info("SCRAPER: B·∫Øt ƒë·∫ßu qu√©t d·ªØ li·ªáu ƒëa ngu·ªìn (10 Web)...")

        # G·ªçi h√†m c√†o ƒëa ngu·ªìn t·ª´ scrapers.py
        items = scrape_all_sources()

        if items:
            count = db.import_content_batch(items)
            msg = f"üì• ƒê√£ qu√©t xong. T√¨m th·∫•y {len(items)} b√†i, l∆∞u m·ªõi {count} b√†i."
            logger.info(msg)
            db.log_health("Scraper", "OK", msg)

            # Reload cache
            global content_records
            content_records = db.get_all_content()
        else:
            db.log_health("Scraper", "WARNING", "Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu n√†o.")

    except Exception as e:
        logger.error(f"L·ªói Scraper: {e}")
        db.log_health("Scraper", "ERROR", str(e))
    finally:
        job_locks["scraper"] = False


# 4. Alive Check
async def alive_check_job(context: ContextTypes.DEFAULT_TYPE):
    db.log_health("System", "ALIVE", "Bot Running")


# 5. B√°o c√°o Admin
async def daily_report_job(context: ContextTypes.DEFAULT_TYPE):
    logger.info("REPORT: T·∫°o b√°o c√°o...")
    errors = db.get_recent_errors(hours=24)
    total_content = len(content_records) if 'content_records' in globals() else 0

    report = f"üìä **B√ÅO C√ÅO NG√ÄY** ({datetime.datetime.now().strftime('%d/%m')})\n"
    report += f"- T·ªïng b√†i h·ªçc (DB): {total_content}\n"
    if not errors:
        report += "‚úÖ H·ªá th·ªëng ·ªïn ƒë·ªãnh."
    else:
        report += f"‚ö†Ô∏è C√≥ {len(errors)} l·ªói trong 24h qua."

    for admin_id in ADMIN_IDS:
        await send_message_safe(context.bot, admin_id, report, parse_mode="Markdown")


# 6. D·ªçn d·∫πp
async def maintenance_job(context: ContextTypes.DEFAULT_TYPE):
    count = db.clean_old_logs(days_keep=30)
    if count > 0:
        msg = f"üßπ ƒê√£ d·ªçn d·∫πp {count} d√≤ng log c≈©."
        for admin_id in ADMIN_IDS:
            await send_message_safe(context.bot, admin_id, msg)


# ==============================================================================
# HANDLERS & MAIN
# ==============================================================================

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    message = update.message
    user_id = message.from_user.id
    username = message.from_user.username or "Unknown"
    message_text = message.text

    logger.info(f"Msg from [{username}]: {message_text}")
    history = context.user_data.setdefault('history', [])
    history.append({"role": "user", "content": message_text})

    sugg_text, sugg_link, sugg_id = get_suggestion_engine(message_text)
    final_feedback = ""
    callback_type = "std"
    callback_id = ""

    if sugg_id:
        final_feedback = f"G·ª£i √Ω t·ª´ DB:\n\nüí° **{sugg_text}**\n{sugg_link}"
        callback_type = "sugg"
        callback_id = sugg_id
        logger.info(f"-> DB Suggestion: {sugg_id}")
    else:
        try:
            final_feedback = await get_gemini_feedback_v3(message_text, history[-10:])
            logger.info("-> Gemini Answer")
        except Exception as e:
            logger.error(f"Gemini Error: {e}")
            final_feedback = get_ai_feedback_v1_0(message_text)
            logger.info("-> Fallback Answer")

    history.append({"role": "ai", "content": final_feedback})
    context.user_data['history'] = history[-20:]

    try:
        db.log_message(user_id, username, message_text, final_feedback)
    except Exception:
        pass

    keyboard = [[
        InlineKeyboardButton("üëç H·ªØu √≠ch", callback_data=f"fb_{callback_type}_{callback_id}_good"),
        InlineKeyboardButton("üëé Kh√¥ng h·ªØu √≠ch", callback_data=f"fb_{callback_type}_{callback_id}_bad"),
    ]]
    await message.reply_text(final_feedback, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode="Markdown")


async def button_click(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    data = query.data
    parts = data.split('_')
    feedback_type = parts[1]
    rating = parts.pop()
    ai_text = query.message.text
    user_id = query.from_user.id
    sugg_id_logged = None

    if feedback_type == "sugg":
        sugg_id_logged = "_".join(parts[2:])
        try:
            db.update_suggestion_score(sugg_id_logged, rating)
        except:
            pass

    try:
        db.log_feedback(user_id, ai_text, rating, sugg_id_logged)
    except:
        pass

    await query.edit_message_text(text=f"{ai_text}\n\n[C·∫£m ∆°n b·∫°n ƒë√£ ƒë√°nh gi√°!]")


async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("Ch√†o b·∫°n! AI Mentor v3.3 (Multi-Source) s·∫µn s√†ng!")


def main():
    logger.info("--- KH·ªûI ƒê·ªòNG AI MENTOR BOT v3.3 (Day 21) ---")
    application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()

    jq = application.job_queue
    # ƒê·∫∑t l·ªãch (Gi√¢y)
    # 1. Nh·∫Øc nh·ªü: 24h
    jq.run_repeating(smart_scheduler_job, interval=86400, first=10)
    # 2. Retry: 5 ph√∫t
    jq.run_repeating(retry_job, interval=300, first=15)
    # 3. Alive Check: 1h
    jq.run_repeating(alive_check_job, interval=3600, first=20)
    # 4. [DAY 21] Auto Feed (6h) - first=30s ƒë·ªÉ test ngay khi kh·ªüi ƒë·ªông
    jq.run_repeating(auto_feed_job, interval=21600, first=30)
    # 5. B√°o c√°o: 24h
    jq.run_repeating(daily_report_job, interval=86400, first=60)
    # 6. D·ªçn d·∫πp: 1 tu·∫ßn
    jq.run_repeating(maintenance_job, interval=604800, first=120)

    application.add_handler(CommandHandler("start", start_command))
    application.add_handler(CallbackQueryHandler(button_click, pattern="^fb_"))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    logger.info("Bot ƒëang ch·∫°y...")
    application.run_polling()


if __name__ == "__main__":
    main()